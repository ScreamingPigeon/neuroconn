{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is used to build the a two-step thresholding procedure (bootstrapping + disparity filter)\n",
    "# The output should be a list of thresholded dPLI matrices for each window per participant\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import signal\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from helpers import aggregated_bootstrapping_and_threshold, apply_aggregated_filter, compute_dPLI\n",
    "\n",
    "# defining input and output directory\n",
    "files_in = '../data/in/subjects/'\n",
    "files_out = '../data/out/subjects/'\n",
    "\n",
    "\n",
    "# loading list of subject names from txt file\n",
    "names = open(\"./names.txt\", \"r\")\n",
    "subject_list = names.read().split('\\n')\n",
    "modes = ['EC', 'EO']\n",
    "\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for subject in subject_list:\n",
    "    for mode in modes:\n",
    "        tc_file = files_out + subject +'/'+mode +'/'+subject'_time_courses.npy'\n",
    "        label_time_courses = np.load(tc_file)\n",
    "        sampling_rate = 512  # in Hz\n",
    "        window_length_seconds = 1  # desired window length in seconds\n",
    "        step_size_seconds = 0.5  # desired step size in seconds\n",
    "\n",
    "        # Convert time to samples\n",
    "        window_length_samples = int(window_length_seconds * sampling_rate)\n",
    "        step_size_samples = int(step_size_seconds * sampling_rate)\n",
    "\n",
    "        # Calculate total duration in samples\n",
    "        num_epochs_per_hemisphere = label_time_courses.shape[0] / 2\n",
    "        duration_per_epoch = label_time_courses.shape[2] / sampling_rate\n",
    "        total_duration_samples = int(num_epochs_per_hemisphere * duration_per_epoch * sampling_rate)\n",
    "\n",
    "        # Compute dPLI for each window\n",
    "        num_windows = int((total_duration_samples - window_length_samples) / step_size_samples) + 1\n",
    "        windowed_dpli_matrices = []\n",
    "\n",
    "        for win_idx in range(num_windows):\n",
    "            start_sample = win_idx * step_size_samples\n",
    "            end_sample = start_sample + window_length_samples\n",
    "\n",
    "            if end_sample > total_duration_samples:\n",
    "                break\n",
    "\n",
    "            start_epoch = start_sample // label_time_courses.shape[2]\n",
    "            start_sample_in_epoch = start_sample % label_time_courses.shape[2]\n",
    "            end_epoch = end_sample // label_time_courses.shape[2]\n",
    "            end_sample_in_epoch = end_sample % label_time_courses.shape[2]\n",
    "\n",
    "            if start_epoch == end_epoch:\n",
    "                windowed_data = label_time_courses[start_epoch, :, start_sample_in_epoch:end_sample_in_epoch]\n",
    "            else:\n",
    "                first_part = label_time_courses[start_epoch, :, start_sample_in_epoch:]\n",
    "                samples_needed_from_second_epoch = window_length_samples - first_part.shape[1]\n",
    "                second_part = label_time_courses[end_epoch, :, :samples_needed_from_second_epoch]\n",
    "                windowed_data = np.concatenate((first_part, second_part), axis=1)\n",
    "\n",
    "            dpli_result = compute_dPLI(windowed_data)\n",
    "            windowed_dpli_matrices.append(dpli_result)\n",
    "            all_graphs.append(dpli_result)\n",
    "\n",
    "        all_graphs.append(windowed_dpli_matrices)\n",
    "\n",
    "print(all_graphs)\n",
    "\n",
    "alpha, thresh = aggregated_bootstrapping_and_threshold(all_graphs)\n",
    "\n",
    "print(alpha, thresh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Convert each windowed dPLI matrix to a graph\n",
    "#         windowed_graphs = [nx.convert_matrix.from_numpy_array(matrix, create_using=nx.DiGraph) for matrix in windowed_dpli_matrices]\n",
    "\n",
    "#         # Perform aggregated bootstrapping and find optimal alpha and upper threshold\n",
    "#         optimal_alpha, upper_threshold = aggregated_bootstrapping_and_threshold(windowed_graphs, num_iterations=1000, percentile=95)\n",
    "\n",
    "#         # Apply the aggregated filter to each windowed graph\n",
    "#         thresholded_dpli_matrices = []\n",
    "#         for G_dPLI in windowed_graphs:\n",
    "#             G_dPLI_thresholded = apply_aggregated_filter(G_dPLI, optimal_alpha, upper_threshold)\n",
    "#             dpli_matrix_thresholded = nx.convert_matrix.to_numpy_array(G_dPLI_thresholded)\n",
    "#             thresholded_dpli_matrices.append(dpli_matrix_thresholded)\n",
    "\n",
    "#         # thresholded_dpli_matrices contains the thresholded dPLI matrices for each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main4",
   "language": "python",
   "name": "main4"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
